{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b5b88cc",
   "metadata": {},
   "source": [
    "**Import Python Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071063d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d92dd",
   "metadata": {},
   "source": [
    "Seaborn is a data visualization library built on top of Matplotlib, providing a high-level interface for\n",
    "creating informative and attractive statistical graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cf4508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb84cd",
   "metadata": {},
   "source": [
    "Matplotlib is a powerful plotting library that enables the creation of a wide variety of static, animated, and \n",
    "interactive visualizations in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0791f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af0902e",
   "metadata": {},
   "source": [
    "NumPy is a powerful library for numerical operations, providing support for large, multi-dimensional arrays \n",
    "and matrices, along with mathematical functions to operate on these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c4280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187dcb1",
   "metadata": {},
   "source": [
    "Pandas is a powerful and popular library for data manipulation and analysis. It provides data structures like \n",
    "DataFrame for efficient handling of structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f5b9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as ctb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597c7df",
   "metadata": {},
   "source": [
    "CatBoost is a machine learning library specifically designed for gradient boosting on decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b74ae8",
   "metadata": {},
   "source": [
    "**Import Python dependencies (functions and classes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fdb77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean \n",
    "\n",
    "from numpy import std\n",
    "\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebe71ce",
   "metadata": {},
   "source": [
    "The mean function is used to calculate the arithmetic mean or average of numerical data.\n",
    "The std function is used to compute the standard deviation of a set of numerical values.\n",
    "The asarray function is used to convert input to an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f718b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a48b1e",
   "metadata": {},
   "source": [
    "The Normalizer class is used for normalizing samples individually to have unit norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b71686a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276cb736",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split : \n",
    "This imports the train_test_split function, which is commonly used to split a dataset into training and testing sets.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score : \n",
    "This imports the cross_val_score function, which is used for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76219fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3831d",
   "metadata": {},
   "source": [
    "from sklearn.metrics import mean_squared_error : \n",
    "This imports the mean_squared_error function, which is a metric used for regression tasks. It calculates the mean squared difference between the actual and predicted values, providing a measure of the model's accuracy.\n",
    "\n",
    "from sklearn.metrics import accuracy_score : \n",
    "This imports the accuracy_score function, which is a classification metric. It measures the accuracy of classification models by comparing the predicted labels to the true labels.\n",
    "\n",
    "from sklearn.metrics import r2_score : \n",
    "This imports the r2_score function, also known as the coefficient of determination. It assesses the goodness of fit of a\n",
    "regression model by indicating the proportion of the variance in the dependent variable that is predictable from the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5748a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72997133",
   "metadata": {},
   "source": [
    "np.random.seed(7): This uses the seed function from the NumPy library to seed the random number generator. The argument (in this case, 7) is an arbitrary value, and setting it ensures reproducibility in random number generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84810cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3b651",
   "metadata": {},
   "source": [
    "from hyperopt import hp: This imports the hp module, which stands for \"hyperparameters.\" Hyperopt is a powerful library for hyperparameter optimization, and the hp module provides a convenient way to define and search through hyperparameter spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b7e0e",
   "metadata": {},
   "source": [
    "**Setting Parameters of Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f74e2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctb_params_reg = {\n",
    "    'learning_rate' : hp.choice('learning_rate' , np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth' : hp.choice('max_depth' , np.arange(5, 16, 5, dtype = int)),\n",
    "    'colsample_bylevel' : hp.choice('colsample_bylevel' , np.arange(0.3, 0.8, 0.1)),\n",
    "    'n_estimators' : 100,\n",
    "    'eval_metric' : 'RMSE'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0b7c2e",
   "metadata": {},
   "source": [
    "This code defines a dictionary ctb_params_reg that represents a search space for hyperparameters used in the CatBoostRegressor model within the context of hyperparameter optimization using Hyperopt.\n",
    "\n",
    "'learning_rate': hp.choice('learning_rate', np.arange(0.05, 0.31, 0.05)): This defines a hyperparameter for the learning rate with a choice space represented by np.arange(0.05, 0.31, 0.05).\n",
    "\n",
    "'max_depth': hp.choice('max_depth', np.arange(5, 16, 5, dtype=int)): This defines a hyperparameter for the maximum depth of trees with a choice space represented by np.arange(5, 16, 5, dtype=int).\n",
    "\n",
    "'colsample_bylevel': hp.choice('colsample_bylevel', np.arange(0.3, 0.8, 0.1)): This defines a hyperparameter for the fraction of features to consider for each split with a choice space represented by np.arange(0.3, 0.8, 0.1).\n",
    "\n",
    "'n_estimators': 100: This sets a fixed value for the number of estimators (trees) in the ensemble to 100.\n",
    "\n",
    "'eval_metric': 'RMSE': This sets the evaluation metric to Root Mean Squared Error (RMSE), which is commonly used for regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b55a07ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctb_params_fit = {\n",
    "    'early_stopping_rounds' : 10,\n",
    "    'verbose' : False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f27885",
   "metadata": {},
   "source": [
    "This code defines a dictionary ctb_params_fit that represents parameters used during the training (fitting) phase of the CatBoostRegressor model.\n",
    "\n",
    "'early_stopping_rounds': 10: This parameter is set to 10, indicating that the training process will stop if the performance metric (evaluated on a validation set) does not improve after 10 consecutive rounds.\n",
    "\n",
    "'verbose': False: This parameter is set to False, which means that the training process will not display detailed progress information. Setting verbose to False can be useful to reduce the amount of output during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d9c7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctb_para = dict()\n",
    "ctb_para['params_reg'] = ctb_params_reg\n",
    "ctb_para['params_fit'] = ctb_params_fit\n",
    "ctb_para['func_loss'] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce638646",
   "metadata": {},
   "source": [
    "This code creates a dictionary ctb_para that combines parameters and functions for configuring the CatBoostRegressor model within the context of hyperparameter optimization and training.\n",
    "\n",
    "ctb_para['params_reg'] = ctb_params_reg: This associates the hyperparameter search space defined earlier (ctb_params_reg) with the key 'params_reg' in the dictionary.\n",
    "\n",
    "ctb_para['params_fit'] = ctb_params_fit: This associates the training parameters defined earlier (ctb_params_fit) with the key 'params_fit' in the dictionary.\n",
    "\n",
    "ctb_para['func_loss'] = lambda y, pred: np.sqrt(mean_squared_error(y, pred)): This associates a loss function with the key 'func_loss' in the dictionary. The loss function is defined as the square root of the mean squared error, which is a common metric for regression tasks. The lambda function takes the true labels (y) and the predicted values (pred) as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e71132",
   "metadata": {},
   "source": [
    "**Creating CatBoostRegressor Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d7b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials, STATUS_OK, STATUS_FAIL\n",
    "\n",
    "class CatOptimizer(object):\n",
    "    def __init__ (self, x_train, x_test, y_train, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def process (self, f_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, f_name)\n",
    "        try:\n",
    "            result = fmin(fn = fn, space = space, algo = algo, max_evals = max_evals, trials = trials)\n",
    "        except Exception as e:\n",
    "            return { 'status' : STATUS_FAIL,\n",
    "                    'exception' : str(e)}\n",
    "        return result, trials\n",
    "    \n",
    "    def cat_reg (self, para):\n",
    "        reg = ctb.CatBoostRegressor(**para['params_reg'])\n",
    "        return self.train_reg(reg, para)\n",
    "    \n",
    "    def train_reg (self, reg, para):\n",
    "        reg.fit(self.x_train, self.y_train, eval_set = [(self.x_train, self.y_train), (self.x_test, self.y_test)],\n",
    "                **para['params_fit'])\n",
    "        pred = reg.predict(self.x_test)\n",
    "        loss = para['func_loss'](self.y_test, pred)\n",
    "        return {'loss' : loss, 'status' : STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18453583",
   "metadata": {},
   "source": [
    "This code defines a Python class CatOptimizer that serves as a wrapper for hyperparameter optimization of a CatBoostRegressor model using the Hyperopt library.\n",
    "\n",
    "The __init__ method initializes the class instance with training and testing data.\n",
    "\n",
    "The process method is a generic method for hyperparameter optimization. It takes the name of a function (f_name), a search space (space), a set of trials (trials), an optimization algorithm (algo), and the maximum number of evaluations (max_evals). It attempts to optimize the specified function using the specified algorithm and search space.\n",
    "\n",
    "The cat_reg method is the specific function to be optimized, creating a CatBoostRegressor model with hyperparameters provided in para['params_reg'].\n",
    "\n",
    "The train_reg method trains the CatBoostRegressor model, evaluates it on a validation set, and computes the loss using the specified loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ac72e",
   "metadata": {},
   "source": [
    "**Reading data from train and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adbb6eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SCORE' 'SS/20' 'FSR/30' 'FQE/20' 'FRU/30' 'TLR/100' 'PU/35' 'QP/40'\n",
      " 'IPR/15' 'FPPP/10' 'RP/100' 'GPH/40' 'GUE/15' 'MS/25' 'GPHD/20' 'GO/100'\n",
      " 'RD/30' 'WD/30' 'ESCS/20' 'PCS/20' 'OI/100' 'PR/100' 'RANK']\n"
     ]
    }
   ],
   "source": [
    "df_t_train = pd.read_csv(\"2021-NIRF_train.csv\")\n",
    "train_data = pd.DataFrame(df_t_train)\n",
    "print(train_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1967d68f",
   "metadata": {},
   "source": [
    "df_t_train = pd.read_csv(\"2021-NIRF_train.csv\"): This line uses Pandas (pd) to read data from a CSV file named \"2021-NIRF_train.csv\" and stores it in a DataFrame called df_t_train.\n",
    "\n",
    "train_data = pd.DataFrame(df_t_train): This line creates a new DataFrame called train_data by copying the data from df_t_train. While this line seems redundant, it's common to create a new DataFrame if you want to manipulate or analyze the data separately without affecting the original DataFrame.\n",
    "\n",
    "print(train_data.columns.values): This line prints the column names of the train_data DataFrame. The columns attribute contains the column labels, and values returns them as a NumPy array. This statement helps to quickly inspect the column names in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a41e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SCORE' 'SS/20' 'FSR/30' 'FQE/20' 'FRU/30' 'TLR/100' 'PU/35' 'QP/40'\n",
      " 'IPR/15' 'FPPP/10' 'RP/100' 'GPH/40' 'GUE/15' 'MS/25' 'GPHD/20' 'GO/100'\n",
      " 'RD/30' 'WD/30' 'ESCS/20' 'PCS/20' 'OI/100' 'PR/100' 'RANK']\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"2021-NIRF_test.csv\")\n",
    "print(test_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd4ca97",
   "metadata": {},
   "source": [
    "test_data = pd.read_csv(\"2021-NIRF_test.csv\"): This line uses Pandas (pd) to read data from a CSV file named \"2021-NIRF_test.csv\" and stores it in a DataFrame called test_data. This is similar to what was done with the training data.\n",
    "\n",
    "print(test_data.columns.values): This line prints the column names of the test_data DataFrame. The columns attribute contains the column labels, and values returns them as a NumPy array. This statement helps to quickly inspect the column names in the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97122d7",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5143dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_data['RANK']\n",
    "test_labels = test_data['RANK']\n",
    "train_features = train_data.drop('RANK', axis = 1)\n",
    "test_features = test_data.drop('RANK', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bfe73e",
   "metadata": {},
   "source": [
    "train_labels = train_data['RANK']: This line extracts the column labeled 'RANK' from the train_data DataFrame and assigns it to the variable train_labels. This assumes that 'RANK' is the target variable or the labels for the training set.\n",
    "\n",
    "test_labels = test_data['RANK']: Similarly, this line extracts the column labeled 'RANK' from the test_data DataFrame and assigns it to the variable test_labels. This assumes that 'RANK' is the target variable or the labels for the test set.\n",
    "\n",
    "train_features = train_data.drop('RANK', axis=1): This line creates a new DataFrame train_features by removing the column labeled 'RANK' from the train_data DataFrame along the columns (axis=1). This DataFrame is now assumed to contain the features used for training.\n",
    "\n",
    "test_features = test_data.drop('RANK', axis=1): Similarly, this line creates a new DataFrame test_features by removing the column labeled 'RANK' from the test_data DataFrame along the columns (axis=1). This DataFrame is assumed to contain the features used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37719026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 22)\n",
      "(20, 22)\n",
      "(190,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cdda36",
   "metadata": {},
   "source": [
    "print(train_features.shape): This line prints the shape of the train_features DataFrame, indicating the number of rows and columns. The output will be in the form (number_of_rows, number_of_columns).\n",
    "\n",
    "print(test_features.shape): Similarly, this line prints the shape of the test_features DataFrame, providing information about the number of rows and columns in the test set.\n",
    "\n",
    "print(train_labels.shape): This line prints the shape of the train_labels Series, indicating the number of elements. Since this represents the labels for the training set, the shape will be a tuple with one element, indicating the total number of labels.\n",
    "\n",
    "print(test_labels.shape): Similarly, this line prints the shape of the test_labels Series, indicating the number of elements in the test set labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c8a34db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_features\n",
    "test_X = test_features\n",
    "train_Y = train_labels\n",
    "test_Y = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cfcb84",
   "metadata": {},
   "source": [
    "train_X = train_features: This line assigns the DataFrame train_features to the variable train_X. This typically represents the feature set used for training machine learning models.\n",
    "\n",
    "test_X = test_features: Similarly, this line assigns the DataFrame test_features to the variable test_X. This typically represents the feature set used for testing or predicting with machine learning models.\n",
    "\n",
    "train_Y = train_labels: This line assigns the Series train_labels to the variable train_Y. This typically represents the target variable or labels corresponding to the training set.\n",
    "\n",
    "test_Y = test_labels: Similarly, this line assigns the Series test_labels to the variable test_Y. This typically represents the target variable or labels corresponding to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacee79d",
   "metadata": {},
   "source": [
    "**Feature Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cc46d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_train = Normalizer().fit(train_X)\n",
    "train_X = transformer_train.transform(train_X)\n",
    "t_test = test_X\n",
    "test_X = transformer_train.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501662c",
   "metadata": {},
   "source": [
    "transformer_train = Normalizer().fit(train_X): This line creates an instance of the Normalizer class from scikit-learn and fits it to the training features (train_X). The fit method calculates the normalization parameters based on the training data.\n",
    "\n",
    "train_X = transformer_train.transform(train_X): This line transforms (normalizes) the training features using the normalization parameters calculated during the fitting step. The transform method applies the normalization to the training set.\n",
    "\n",
    "t_test = test_X: This line creates a copy of the original test features and assigns it to the variable t_test. This line is not necessary for the normalization process but might be used for comparison or other purposes.\n",
    "\n",
    "test_X = transformer_train.transform(test_X): This line applies the same normalization transformation to the test features using the parameters learned from the training set. It ensures consistency in the normalization process between the training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28cc8d",
   "metadata": {},
   "source": [
    "**Creating Result class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a41c4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result():\n",
    "    def __init__ (self, y_true):\n",
    "        self.results = pd.DataFrame({'true_test' : y_true})\n",
    "        self.metrics = pd.DataFrame(columns = ('model','rmse','r2'))\n",
    "    def record (self, model, y_pred):\n",
    "        y_true = self.results.true_test.values\n",
    "        y_pred = pd.Series(y_pred, name = model+'_pred')\n",
    "        self.results = pd.concat([self.results, y_pred], axis = 1)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true,y_pred))\n",
    "        r_squared = r2_score(y_true, y_pred)\n",
    "        row_loc = len(self.metrics) + 1\n",
    "        self.metrics.loc[row_loc] = [model, rmse, r_squared]\n",
    "    def get_metrics(self):\n",
    "        return self.metrics\n",
    "    def get_results(self):\n",
    "        return self.results\n",
    "    \n",
    "res_r = Result(test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101f647",
   "metadata": {},
   "source": [
    "def __init__(self, y_true): This is the constructor method that initializes an instance of the Result class. It takes a parameter y_true, representing the true values for the test set, and creates two DataFrames: results to store the true values and predictions, and metrics to store evaluation metrics.\n",
    "\n",
    "def record(self, model, y_pred): This method records the predictions and calculates evaluation metrics for a given model. It takes the model name (model) and the predicted values (y_pred) as parameters.\n",
    "\n",
    "def get_metrics(self): This method returns the DataFrame containing the recorded metrics.\n",
    "\n",
    "def get_results(self): This method returns the DataFrame containing the true values and predictions.\n",
    "\n",
    "res_r = Result(test_Y): An instance of the Result class is created with the true values for the test set (test_Y) passed as a parameter, and it is assigned to the variable res_r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90fc51b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 100/100 [25:50<00:00, 15.51s/trial, best loss: 7.836680825832662]\n",
      "({'colsample_bylevel': 3, 'learning_rate': 3, 'max_depth': 0}, <hyperopt.base.Trials object at 0x0000022E13521050>)\n"
     ]
    }
   ],
   "source": [
    "opt_model = CatOptimizer(train_X, test_X, train_Y, test_Y)\n",
    "ctb_opt = opt_model.process(f_name = 'cat_reg', space = ctb_para, trials = Trials(), algo = tpe.suggest, max_evals = 100)\n",
    "print(ctb_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced945b6",
   "metadata": {},
   "source": [
    "opt_model = CatOptimizer(train_X, test_X, train_Y, test_Y): This line creates an instance of the CatOptimizer class, initializing it with the training and testing data (train_X, test_X, train_Y, test_Y).\n",
    "\n",
    "ctb_opt = opt_model.process(f_name='cat_reg', space=ctb_para, trials=Trials(), algo=tpe.suggest, max_evals=100): This line uses the process method of the opt_model instance to perform hyperparameter optimization. It optimizes the cat_reg function (CatBoostRegressor) using the hyperparameter search space defined in ctb_para, with the TPE (Tree-structured Parzen Estimator) algorithm, and a maximum of 100 evaluations. The result is stored in the variable ctb_opt.\n",
    "\n",
    "print(ctb_opt): This line prints the result of the hyperparameter optimization, which typically includes the best hyperparameters found and information about the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96454a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p = {'learning_rate' : np.arange(0.05, 0.31, 0.05)[ctb_opt[0]['learning_rate']],\n",
    "         'max_depth' : np.arange(5, 16, 1, dtype = int)[ctb_opt[0]['max_depth']],\n",
    "         'colsample_bylevel' : np.arange(0.3, 0.8, 0.1)[ctb_opt[0]['colsample_bylevel']]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b72e1",
   "metadata": {},
   "source": [
    "'learning_rate': np.arange(0.05, 0.31, 0.05)[ctb_opt[0]['learning_rate']]: This line retrieves the optimized learning rate value from the ctb_opt result using the index specified by ctb_opt[0]['learning_rate']. It then uses this index to select the corresponding value from the array generated by np.arange(0.05, 0.31, 0.05).\n",
    "\n",
    "'max_depth': np.arange(5, 16, 1, dtype=int)[ctb_opt[0]['max_depth']]: Similarly, this line retrieves the optimized max depth value from the ctb_opt result and selects the corresponding value from the array generated by np.arange(5, 16, 1, dtype=int).\n",
    "\n",
    "'colsample_bylevel': np.arange(0.3, 0.8, 0.1)[ctb_opt[0]['colsample_bylevel']]: This line retrieves the optimized colsample_bylevel value from the ctb_opt result and selects the corresponding value from the array generated by np.arange(0.3, 0.8, 0.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2c7ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ctb.CatBoostRegressor( verbose = 0, n_estimators = 100, colsample_bylevel = best_p['colsample_bylevel'],\n",
    "                             learning_rate = best_p['learning_rate'], max_depth = best_p['max_depth'], \n",
    "                             early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd225af",
   "metadata": {},
   "source": [
    "model = ctb.CatBoostRegressor(...): This line creates an instance of the CatBoostRegressor model from the CatBoost library for regression tasks.\n",
    "\n",
    "verbose=0: This parameter sets the verbosity level to 0, meaning no output will be printed during the training process.\n",
    "\n",
    "n_estimators=100: This sets the number of trees (estimators) in the ensemble to 100.\n",
    "\n",
    "colsample_bylevel=best_p['colsample_bylevel']: This sets the fraction of features to consider for each split during training, using the value obtained from the hyperparameter optimization process.\n",
    "\n",
    "learning_rate=best_p['learning_rate']: This sets the learning rate for the model, using the value obtained from the hyperparameter optimization process.\n",
    "\n",
    "max_depth=best_p['max_depth']: This sets the maximum depth of the trees in the ensemble, using the value obtained from the hyperparameter optimization process.\n",
    "\n",
    "early_stopping_rounds=10: This parameter sets the early stopping criteria. Training will stop after 10 rounds if the evaluation metric does not improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "757ee069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x22e134c7a50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eccaa1",
   "metadata": {},
   "source": [
    "model.fit(train_X, train_Y): This line trains the CatBoostRegressor model (model) on the training data. The train_X variable represents the feature matrix (input variables), and train_Y represents the target variable or labels for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38344659",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b916b3",
   "metadata": {},
   "source": [
    "pred_y = model.predict(test_X): This line applies the trained CatBoostRegressor model (model) to the test features (test_X) to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b33bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_r.record('Cat Boost', pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd25dd",
   "metadata": {},
   "source": [
    "res_r.record('Cat Boost', pred_y): This line calls the record method of the res_r instance, where:\n",
    "'Cat Boost' is passed as the model name.\n",
    "pred_y represents the predicted values obtained from the CatBoostRegressor model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6778f",
   "metadata": {},
   "source": [
    "**Final R2 and RMSE value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ed1be5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat Boost</td>\n",
       "      <td>7.663461</td>\n",
       "      <td>0.98169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model      rmse       r2\n",
       "1  Cat Boost  7.663461  0.98169"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_r.get_metrics().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4bb79",
   "metadata": {},
   "source": [
    "res_r.get_metrics(): This calls the get_metrics method of the res_r instance, which returns the DataFrame containing the recorded evaluation metrics for different models.\n",
    "\n",
    ".head(): This method is used to display the first few rows of the DataFrame, providing a quick overview of the recorded metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec5b2b3",
   "metadata": {},
   "source": [
    "**Utilization of CatBoost instead of other models:**\n",
    "The CatBoost model was chosen for its distinctive strengths in handling tabular data and regression scenarios. CatBoost, short for \"Categorical Boosting,\" possesses several key advantages that contribute to its efficacy:\n",
    "\n",
    "**Handling Categorical Features:**\n",
    "CatBoost inherently handles categorical features without the need for extensive preprocessing. This is particularly beneficial when dealing with datasets containing a mix of numerical and categorical variables.\n",
    "\n",
    "**Robust Performance:**\n",
    "CatBoost is known for its robustness and ability to perform well \"out of the box.\" It requires minimal hyperparameter tuning compared to other gradient boosting algorithms, making it a suitable choice for efficient model development.\n",
    "\n",
    "**Optimized Tree Building:**\n",
    "The algorithm employs a novel method for decision tree construction, optimizing the process and resulting in faster training times. This is especially advantageous for large datasets or scenarios where computational efficiency is crucial.\n",
    "\n",
    "**Built-in Regularization:**\n",
    "CatBoost incorporates built-in regularization techniques, which contribute to enhanced model generalization and mitigating overfitting. This is valuable when working with complex datasets to ensure the model's reliability on unseen data.\n",
    "\n",
    "**Handling Missing Data:**\n",
    "CatBoost has effective strategies for handling missing data, reducing the need for explicit imputation techniques. This is advantageous when working with real-world datasets that often contain missing values.\n",
    "\n",
    "**Gradient Boosting with Categorical Features:**\n",
    "CatBoost employs a gradient boosting framework, effectively capturing complex relationships within the data. The incorporation of categorical features into the boosting process enhances its ability to model intricate patterns in diverse datasets.\n",
    "\n",
    "In summary, the CatBoost model presents a compelling solution for regression tasks, offering a balance between performance, ease of use, and robustness, particularly in scenarios where datasets exhibit a mix of categorical and numerical features. Its ability to handle complexities inherent in real-world data makes it a prudent choice for achieving accurate and reliable regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f5cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
